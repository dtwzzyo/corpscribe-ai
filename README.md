# CorpScribe AI 

**CorpScribe AI** — это полнофункциональный прототип локальной и безопасной RAG-системы (Retrieval-Augmented Generation), предназначенный для ответов на вопросы по сложной внутренней документации.

Проект демонстрирует end-to-end цикл разработки ML-сервиса: от создания и итеративной отладки RAG-пайплайна до реализации админ-панели и упаковки в Docker.

---

##  Демонстрация


**Чат с Ассистентом:**
![Chat UI](chat_screenshot.png)

**Админ-панель:**
![Admin UI](admin_screenshot.png)

---

##  Технический стек

*   **LLM Сервер:** `Ollama` (локальный инференс модели `Mistral 7B`)
*   **Бэкенд:** `Python`, `Flask` (API-сервер)
*   **Фронтенд:** `Streamlit` (интерактивный UI)
*   **Оркестрация RAG:** `LangChain`
*   **Векторная база:** `ChromaDB`
*   **Парсинг документов:** `Unstructured` (для PDF, TXT)
*   **Улучшение поиска:** `Flashrank` (локальный ре-ранкер)
*   **Контейнеризация:** `Docker`

---

##  Ключевые возможности

*   **Продвинутый RAG-пайплайн:** Система использует двухэтапный поиск: быстрый векторный поиск по `ChromaDB` и точный ре-ранкинг с помощью `Flashrank` для максимальной релевантности ответов.
*   **Поддержка разных форматов:** "Умный" парсинг `.pdf` и `.txt` файлов с помощью библиотеки `Unstructured`, сохраняющий структуру документа.
*   **Интерактивная Админ-панель:** Полноценный UI на Streamlit, позволяющий не-техническим специалистам загружать/удалять документы и запускать переиндексацию базы знаний одной кнопкой.
*   **API-first дизайн:** Вся логика инкапсулирована в Flask API с эндпоинтами для чата и управления документами.
*   **Полная контейнеризация:** Проект упакован в `Dockerfile` для простого и воспроизводимого запуска в любой среде.

---

##  Инженерный путь: отладка и тюнинг

Ключевой частью проекта была не разработка, а итеративная отладка RAG-пайплайна для работы со сложными документами:

1.  **Проблема:** Изначально система давала неточные ответы или "галлюцинировала" на больших PDF.
2.  **Диагностика:** С помощью отладочных скриптов было выявлено, что базовый ретривер не находил релевантные фрагменты текста.
3.  **Итерация 1 (Тюнинг чанков):** Эксперименты с `chunk_size` и `chunk_overlap` показали улучшение, но не решали проблему "шума" в контексте.
4.  **Итерация 2 (Внедрение Ре-ранкера):** Для отсеивания нерелевантных документов был добавлен `Flashrank`. Это значительно повысило точность, но выявило новую проблему.
5.  **Итерация 3 (Смена парсера):** Было обнаружено, что стандартный `PyPDFLoader` разрушает структуру документа. Он был заменен на `UnstructuredFileLoader`, что позволило парсить PDF с учетом его семантической структуры.

Этот процесс демонстрирует практические навыки тюнинга и оптимизации RAG-систем.

---

## Как запустить

**Предварительные требования:**
*   Docker и Docker Compose
*   Ollama, запущенная на ПК с GPU в той же локальной сети.

**1. Клонируйте репозиторий:**
```bash
git clone https://github.com/dtwzzyo/corpscribe-ai
cd corpscribe-ai
```

**2. Настройте LLM-сервер:**
*   Убедитесь, что ваш `Ollama` сервер доступен по сети.
*   Создайте файл `app.py` и `ingest.py` и впишите IP-адрес вашего ПК в переменную `PC_IP_ADDRESS`.

**3. Создайте папку `docs` и положите в нее ваши `.txt` файлы.**

**4. Соберите и запустите Docker-контейнер:**
```bash
docker build -t corpscribe-ai .
docker run -p 8501:8501 -p 5001:5001 corpscribe-ai
```

**5. Откройте приложение в браузере:**
Перейдите по адресу `http://localhost:8501`.
